{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c99f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7757e53-4fb4-4317-9a1b-339877628de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data/MAUS/Data/Raw_data/003/inf_gsr.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/003/record.xlsx</th>\n",
       "      <th>data/MAUS/Data/Raw_data/003/inf_ppg.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/003/pixart.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/003/pixart_resting.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/003/inf_ecg.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/003/inf_resting.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/006/inf_gsr.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/006/record.xlsx</th>\n",
       "      <th>data/MAUS/Data/Raw_data/006/inf_ppg.csv</th>\n",
       "      <th>...</th>\n",
       "      <th>data/MAUS/Data/Raw_data/017/pixart_resting.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/017/inf_ecg.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/017/inf_resting.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/025/inf_gsr.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/025/record.xlsx</th>\n",
       "      <th>data/MAUS/Data/Raw_data/025/inf_ppg.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/025/pixart.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/025/pixart_resting.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/025/inf_ecg.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/025/inf_resting.csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trial 1:0back</th>\n",
       "      <td>1.500527</td>\n",
       "      <td>1.500527</td>\n",
       "      <td>35.300871</td>\n",
       "      <td>-1.475754e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.124355</td>\n",
       "      <td>1.124355</td>\n",
       "      <td>35.338599</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.254841</td>\n",
       "      <td>0.254841</td>\n",
       "      <td>35.277786</td>\n",
       "      <td>-1.096793e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial 2:2back</th>\n",
       "      <td>2.111009</td>\n",
       "      <td>2.111009</td>\n",
       "      <td>35.321742</td>\n",
       "      <td>-1.477304e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.133808</td>\n",
       "      <td>2.133808</td>\n",
       "      <td>35.249949</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.295053</td>\n",
       "      <td>0.295053</td>\n",
       "      <td>35.244401</td>\n",
       "      <td>-1.054236e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial 3:3back</th>\n",
       "      <td>2.569572</td>\n",
       "      <td>2.569572</td>\n",
       "      <td>35.326562</td>\n",
       "      <td>-1.392519e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.393774</td>\n",
       "      <td>2.393774</td>\n",
       "      <td>35.246081</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.427711</td>\n",
       "      <td>0.427711</td>\n",
       "      <td>35.253023</td>\n",
       "      <td>-1.008712e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial 4:2back</th>\n",
       "      <td>3.168827</td>\n",
       "      <td>3.168827</td>\n",
       "      <td>35.314358</td>\n",
       "      <td>-1.396429e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.164930</td>\n",
       "      <td>2.164930</td>\n",
       "      <td>35.272872</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.499978</td>\n",
       "      <td>0.499978</td>\n",
       "      <td>35.283378</td>\n",
       "      <td>-9.339621e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial 5:3back</th>\n",
       "      <td>3.034902</td>\n",
       "      <td>3.034902</td>\n",
       "      <td>35.314829</td>\n",
       "      <td>-1.413565e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.338570</td>\n",
       "      <td>2.338570</td>\n",
       "      <td>35.257283</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.499743</td>\n",
       "      <td>0.499743</td>\n",
       "      <td>35.265255</td>\n",
       "      <td>-8.911006e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial 6:0back</th>\n",
       "      <td>2.826070</td>\n",
       "      <td>2.826070</td>\n",
       "      <td>35.310509</td>\n",
       "      <td>-1.346514e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.843490</td>\n",
       "      <td>1.843490</td>\n",
       "      <td>35.313281</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537602</td>\n",
       "      <td>0.537602</td>\n",
       "      <td>35.255850</td>\n",
       "      <td>-8.770217e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               data/MAUS/Data/Raw_data/003/inf_gsr.csv  \\\n",
       "Trial 1:0back                                 1.500527   \n",
       "Trial 2:2back                                 2.111009   \n",
       "Trial 3:3back                                 2.569572   \n",
       "Trial 4:2back                                 3.168827   \n",
       "Trial 5:3back                                 3.034902   \n",
       "Trial 6:0back                                 2.826070   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/003/record.xlsx  \\\n",
       "Trial 1:0back                                 1.500527   \n",
       "Trial 2:2back                                 2.111009   \n",
       "Trial 3:3back                                 2.569572   \n",
       "Trial 4:2back                                 3.168827   \n",
       "Trial 5:3back                                 3.034902   \n",
       "Trial 6:0back                                 2.826070   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/003/inf_ppg.csv  \\\n",
       "Trial 1:0back                                35.300871   \n",
       "Trial 2:2back                                35.321742   \n",
       "Trial 3:3back                                35.326562   \n",
       "Trial 4:2back                                35.314358   \n",
       "Trial 5:3back                                35.314829   \n",
       "Trial 6:0back                                35.310509   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/003/pixart.csv  \\\n",
       "Trial 1:0back                           -1.475754e+06   \n",
       "Trial 2:2back                           -1.477304e+06   \n",
       "Trial 3:3back                           -1.392519e+06   \n",
       "Trial 4:2back                           -1.396429e+06   \n",
       "Trial 5:3back                           -1.413565e+06   \n",
       "Trial 6:0back                           -1.346514e+06   \n",
       "\n",
       "              data/MAUS/Data/Raw_data/003/pixart_resting.csv  \\\n",
       "Trial 1:0back                                            NaN   \n",
       "Trial 2:2back                                            NaN   \n",
       "Trial 3:3back                                            NaN   \n",
       "Trial 4:2back                                            NaN   \n",
       "Trial 5:3back                                            NaN   \n",
       "Trial 6:0back                                            NaN   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/003/inf_ecg.csv  \\\n",
       "Trial 1:0back                                 0.000004   \n",
       "Trial 2:2back                                 0.000015   \n",
       "Trial 3:3back                                -0.000021   \n",
       "Trial 4:2back                                 0.000035   \n",
       "Trial 5:3back                                 0.000028   \n",
       "Trial 6:0back                                 0.000048   \n",
       "\n",
       "              data/MAUS/Data/Raw_data/003/inf_resting.csv  \\\n",
       "Trial 1:0back                                         NaN   \n",
       "Trial 2:2back                                         NaN   \n",
       "Trial 3:3back                                         NaN   \n",
       "Trial 4:2back                                         NaN   \n",
       "Trial 5:3back                                         NaN   \n",
       "Trial 6:0back                                         NaN   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/006/inf_gsr.csv  \\\n",
       "Trial 1:0back                                 1.124355   \n",
       "Trial 2:2back                                 2.133808   \n",
       "Trial 3:3back                                 2.393774   \n",
       "Trial 4:2back                                 2.164930   \n",
       "Trial 5:3back                                 2.338570   \n",
       "Trial 6:0back                                 1.843490   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/006/record.xlsx  \\\n",
       "Trial 1:0back                                 1.124355   \n",
       "Trial 2:2back                                 2.133808   \n",
       "Trial 3:3back                                 2.393774   \n",
       "Trial 4:2back                                 2.164930   \n",
       "Trial 5:3back                                 2.338570   \n",
       "Trial 6:0back                                 1.843490   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/006/inf_ppg.csv  ...  \\\n",
       "Trial 1:0back                                35.338599  ...   \n",
       "Trial 2:2back                                35.249949  ...   \n",
       "Trial 3:3back                                35.246081  ...   \n",
       "Trial 4:2back                                35.272872  ...   \n",
       "Trial 5:3back                                35.257283  ...   \n",
       "Trial 6:0back                                35.313281  ...   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/017/pixart_resting.csv  \\\n",
       "Trial 1:0back                                             NaN   \n",
       "Trial 2:2back                                             NaN   \n",
       "Trial 3:3back                                             NaN   \n",
       "Trial 4:2back                                             NaN   \n",
       "Trial 5:3back                                             NaN   \n",
       "Trial 6:0back                                             NaN   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/017/inf_ecg.csv  \\\n",
       "Trial 1:0back                                -0.000047   \n",
       "Trial 2:2back                                 0.000054   \n",
       "Trial 3:3back                                -0.000059   \n",
       "Trial 4:2back                                -0.000054   \n",
       "Trial 5:3back                                 0.000047   \n",
       "Trial 6:0back                                -0.000031   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/017/inf_resting.csv  \\\n",
       "Trial 1:0back                                          NaN   \n",
       "Trial 2:2back                                          NaN   \n",
       "Trial 3:3back                                          NaN   \n",
       "Trial 4:2back                                          NaN   \n",
       "Trial 5:3back                                          NaN   \n",
       "Trial 6:0back                                          NaN   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/025/inf_gsr.csv  \\\n",
       "Trial 1:0back                                 0.254841   \n",
       "Trial 2:2back                                 0.295053   \n",
       "Trial 3:3back                                 0.427711   \n",
       "Trial 4:2back                                 0.499978   \n",
       "Trial 5:3back                                 0.499743   \n",
       "Trial 6:0back                                 0.537602   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/025/record.xlsx  \\\n",
       "Trial 1:0back                                 0.254841   \n",
       "Trial 2:2back                                 0.295053   \n",
       "Trial 3:3back                                 0.427711   \n",
       "Trial 4:2back                                 0.499978   \n",
       "Trial 5:3back                                 0.499743   \n",
       "Trial 6:0back                                 0.537602   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/025/inf_ppg.csv  \\\n",
       "Trial 1:0back                                35.277786   \n",
       "Trial 2:2back                                35.244401   \n",
       "Trial 3:3back                                35.253023   \n",
       "Trial 4:2back                                35.283378   \n",
       "Trial 5:3back                                35.265255   \n",
       "Trial 6:0back                                35.255850   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/025/pixart.csv  \\\n",
       "Trial 1:0back                           -1.096793e+06   \n",
       "Trial 2:2back                           -1.054236e+06   \n",
       "Trial 3:3back                           -1.008712e+06   \n",
       "Trial 4:2back                           -9.339621e+05   \n",
       "Trial 5:3back                           -8.911006e+05   \n",
       "Trial 6:0back                           -8.770217e+05   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/025/pixart_resting.csv  \\\n",
       "Trial 1:0back                                             NaN   \n",
       "Trial 2:2back                                             NaN   \n",
       "Trial 3:3back                                             NaN   \n",
       "Trial 4:2back                                             NaN   \n",
       "Trial 5:3back                                             NaN   \n",
       "Trial 6:0back                                             NaN   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/025/inf_ecg.csv  \\\n",
       "Trial 1:0back                                -0.000094   \n",
       "Trial 2:2back                                -0.000026   \n",
       "Trial 3:3back                                -0.000045   \n",
       "Trial 4:2back                                -0.000006   \n",
       "Trial 5:3back                                 0.000093   \n",
       "Trial 6:0back                                -0.000017   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/025/inf_resting.csv  \n",
       "Trial 1:0back                                          NaN  \n",
       "Trial 2:2back                                          NaN  \n",
       "Trial 3:3back                                          NaN  \n",
       "Trial 4:2back                                          NaN  \n",
       "Trial 5:3back                                          NaN  \n",
       "Trial 6:0back                                          NaN  \n",
       "\n",
       "[6 rows x 154 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = pathlib.Path(\"data/MAUS/Data/Raw_data\")\n",
    "\n",
    "final_data = pd.DataFrame()\n",
    "\n",
    "for person in data_path.iterdir():\n",
    "    for ele in pathlib.Path(person).iterdir():\n",
    "        \n",
    "        # get the data and format it\n",
    "        if str(ele)[-3:] == 'csv':\n",
    "            current_data = pd.read_csv(ele)\n",
    "            formatted_data = current_data.mean(axis=0)\n",
    "        \n",
    "        final_data[str(ele)] = formatted_data\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c58fa4fb-896f-4e17-b883-7b02826e9c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data/MAUS/Data/Raw_data/003/inf_gsr.csv                 1.500527\n",
       "data/MAUS/Data/Raw_data/003/record.xlsx                 1.500527\n",
       "data/MAUS/Data/Raw_data/003/inf_ppg.csv                35.300871\n",
       "data/MAUS/Data/Raw_data/003/pixart.csv           -1475753.576976\n",
       "data/MAUS/Data/Raw_data/003/pixart_resting.csv               NaN\n",
       "                                                       ...      \n",
       "data/MAUS/Data/Raw_data/025/inf_ppg.csv                35.277786\n",
       "data/MAUS/Data/Raw_data/025/pixart.csv           -1096792.735533\n",
       "data/MAUS/Data/Raw_data/025/pixart_resting.csv               NaN\n",
       "data/MAUS/Data/Raw_data/025/inf_ecg.csv                -0.000094\n",
       "data/MAUS/Data/Raw_data/025/inf_resting.csv                  NaN\n",
       "Name: Trial 1:0back, Length: 154, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for ele in final_data.transpose().iloc[:,0]:\n",
    "    print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90af7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
