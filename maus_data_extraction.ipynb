{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c99f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7757e53-4fb4-4317-9a1b-339877628de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n",
      "/tmp/ipykernel_13102/3538318208.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data[str(ele)] = formatted_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data/MAUS/Data/Raw_data/003/inf_gsr.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/003/record.xlsx</th>\n",
       "      <th>data/MAUS/Data/Raw_data/003/inf_ppg.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/003/pixart.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/003/pixart_resting.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/003/inf_ecg.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/003/inf_resting.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/006/inf_gsr.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/006/record.xlsx</th>\n",
       "      <th>data/MAUS/Data/Raw_data/006/inf_ppg.csv</th>\n",
       "      <th>...</th>\n",
       "      <th>data/MAUS/Data/Raw_data/017/pixart_resting.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/017/inf_ecg.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/017/inf_resting.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/025/inf_gsr.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/025/record.xlsx</th>\n",
       "      <th>data/MAUS/Data/Raw_data/025/inf_ppg.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/025/pixart.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/025/pixart_resting.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/025/inf_ecg.csv</th>\n",
       "      <th>data/MAUS/Data/Raw_data/025/inf_resting.csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trial 1:0back</th>\n",
       "      <td>1.500527</td>\n",
       "      <td>1.500527</td>\n",
       "      <td>35.300871</td>\n",
       "      <td>-1.475754e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.124355</td>\n",
       "      <td>1.124355</td>\n",
       "      <td>35.338599</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.254841</td>\n",
       "      <td>0.254841</td>\n",
       "      <td>35.277786</td>\n",
       "      <td>-1.096793e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial 2:2back</th>\n",
       "      <td>2.111009</td>\n",
       "      <td>2.111009</td>\n",
       "      <td>35.321742</td>\n",
       "      <td>-1.477304e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.133808</td>\n",
       "      <td>2.133808</td>\n",
       "      <td>35.249949</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.295053</td>\n",
       "      <td>0.295053</td>\n",
       "      <td>35.244401</td>\n",
       "      <td>-1.054236e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial 3:3back</th>\n",
       "      <td>2.569572</td>\n",
       "      <td>2.569572</td>\n",
       "      <td>35.326562</td>\n",
       "      <td>-1.392519e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.393774</td>\n",
       "      <td>2.393774</td>\n",
       "      <td>35.246081</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.427711</td>\n",
       "      <td>0.427711</td>\n",
       "      <td>35.253023</td>\n",
       "      <td>-1.008712e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial 4:2back</th>\n",
       "      <td>3.168827</td>\n",
       "      <td>3.168827</td>\n",
       "      <td>35.314358</td>\n",
       "      <td>-1.396429e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.164930</td>\n",
       "      <td>2.164930</td>\n",
       "      <td>35.272872</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.499978</td>\n",
       "      <td>0.499978</td>\n",
       "      <td>35.283378</td>\n",
       "      <td>-9.339621e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial 5:3back</th>\n",
       "      <td>3.034902</td>\n",
       "      <td>3.034902</td>\n",
       "      <td>35.314829</td>\n",
       "      <td>-1.413565e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.338570</td>\n",
       "      <td>2.338570</td>\n",
       "      <td>35.257283</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.499743</td>\n",
       "      <td>0.499743</td>\n",
       "      <td>35.265255</td>\n",
       "      <td>-8.911006e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial 6:0back</th>\n",
       "      <td>2.826070</td>\n",
       "      <td>2.826070</td>\n",
       "      <td>35.310509</td>\n",
       "      <td>-1.346514e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.843490</td>\n",
       "      <td>1.843490</td>\n",
       "      <td>35.313281</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537602</td>\n",
       "      <td>0.537602</td>\n",
       "      <td>35.255850</td>\n",
       "      <td>-8.770217e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               data/MAUS/Data/Raw_data/003/inf_gsr.csv  \\\n",
       "Trial 1:0back                                 1.500527   \n",
       "Trial 2:2back                                 2.111009   \n",
       "Trial 3:3back                                 2.569572   \n",
       "Trial 4:2back                                 3.168827   \n",
       "Trial 5:3back                                 3.034902   \n",
       "Trial 6:0back                                 2.826070   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/003/record.xlsx  \\\n",
       "Trial 1:0back                                 1.500527   \n",
       "Trial 2:2back                                 2.111009   \n",
       "Trial 3:3back                                 2.569572   \n",
       "Trial 4:2back                                 3.168827   \n",
       "Trial 5:3back                                 3.034902   \n",
       "Trial 6:0back                                 2.826070   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/003/inf_ppg.csv  \\\n",
       "Trial 1:0back                                35.300871   \n",
       "Trial 2:2back                                35.321742   \n",
       "Trial 3:3back                                35.326562   \n",
       "Trial 4:2back                                35.314358   \n",
       "Trial 5:3back                                35.314829   \n",
       "Trial 6:0back                                35.310509   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/003/pixart.csv  \\\n",
       "Trial 1:0back                           -1.475754e+06   \n",
       "Trial 2:2back                           -1.477304e+06   \n",
       "Trial 3:3back                           -1.392519e+06   \n",
       "Trial 4:2back                           -1.396429e+06   \n",
       "Trial 5:3back                           -1.413565e+06   \n",
       "Trial 6:0back                           -1.346514e+06   \n",
       "\n",
       "              data/MAUS/Data/Raw_data/003/pixart_resting.csv  \\\n",
       "Trial 1:0back                                            NaN   \n",
       "Trial 2:2back                                            NaN   \n",
       "Trial 3:3back                                            NaN   \n",
       "Trial 4:2back                                            NaN   \n",
       "Trial 5:3back                                            NaN   \n",
       "Trial 6:0back                                            NaN   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/003/inf_ecg.csv  \\\n",
       "Trial 1:0back                                 0.000004   \n",
       "Trial 2:2back                                 0.000015   \n",
       "Trial 3:3back                                -0.000021   \n",
       "Trial 4:2back                                 0.000035   \n",
       "Trial 5:3back                                 0.000028   \n",
       "Trial 6:0back                                 0.000048   \n",
       "\n",
       "              data/MAUS/Data/Raw_data/003/inf_resting.csv  \\\n",
       "Trial 1:0back                                         NaN   \n",
       "Trial 2:2back                                         NaN   \n",
       "Trial 3:3back                                         NaN   \n",
       "Trial 4:2back                                         NaN   \n",
       "Trial 5:3back                                         NaN   \n",
       "Trial 6:0back                                         NaN   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/006/inf_gsr.csv  \\\n",
       "Trial 1:0back                                 1.124355   \n",
       "Trial 2:2back                                 2.133808   \n",
       "Trial 3:3back                                 2.393774   \n",
       "Trial 4:2back                                 2.164930   \n",
       "Trial 5:3back                                 2.338570   \n",
       "Trial 6:0back                                 1.843490   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/006/record.xlsx  \\\n",
       "Trial 1:0back                                 1.124355   \n",
       "Trial 2:2back                                 2.133808   \n",
       "Trial 3:3back                                 2.393774   \n",
       "Trial 4:2back                                 2.164930   \n",
       "Trial 5:3back                                 2.338570   \n",
       "Trial 6:0back                                 1.843490   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/006/inf_ppg.csv  ...  \\\n",
       "Trial 1:0back                                35.338599  ...   \n",
       "Trial 2:2back                                35.249949  ...   \n",
       "Trial 3:3back                                35.246081  ...   \n",
       "Trial 4:2back                                35.272872  ...   \n",
       "Trial 5:3back                                35.257283  ...   \n",
       "Trial 6:0back                                35.313281  ...   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/017/pixart_resting.csv  \\\n",
       "Trial 1:0back                                             NaN   \n",
       "Trial 2:2back                                             NaN   \n",
       "Trial 3:3back                                             NaN   \n",
       "Trial 4:2back                                             NaN   \n",
       "Trial 5:3back                                             NaN   \n",
       "Trial 6:0back                                             NaN   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/017/inf_ecg.csv  \\\n",
       "Trial 1:0back                                -0.000047   \n",
       "Trial 2:2back                                 0.000054   \n",
       "Trial 3:3back                                -0.000059   \n",
       "Trial 4:2back                                -0.000054   \n",
       "Trial 5:3back                                 0.000047   \n",
       "Trial 6:0back                                -0.000031   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/017/inf_resting.csv  \\\n",
       "Trial 1:0back                                          NaN   \n",
       "Trial 2:2back                                          NaN   \n",
       "Trial 3:3back                                          NaN   \n",
       "Trial 4:2back                                          NaN   \n",
       "Trial 5:3back                                          NaN   \n",
       "Trial 6:0back                                          NaN   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/025/inf_gsr.csv  \\\n",
       "Trial 1:0back                                 0.254841   \n",
       "Trial 2:2back                                 0.295053   \n",
       "Trial 3:3back                                 0.427711   \n",
       "Trial 4:2back                                 0.499978   \n",
       "Trial 5:3back                                 0.499743   \n",
       "Trial 6:0back                                 0.537602   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/025/record.xlsx  \\\n",
       "Trial 1:0back                                 0.254841   \n",
       "Trial 2:2back                                 0.295053   \n",
       "Trial 3:3back                                 0.427711   \n",
       "Trial 4:2back                                 0.499978   \n",
       "Trial 5:3back                                 0.499743   \n",
       "Trial 6:0back                                 0.537602   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/025/inf_ppg.csv  \\\n",
       "Trial 1:0back                                35.277786   \n",
       "Trial 2:2back                                35.244401   \n",
       "Trial 3:3back                                35.253023   \n",
       "Trial 4:2back                                35.283378   \n",
       "Trial 5:3back                                35.265255   \n",
       "Trial 6:0back                                35.255850   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/025/pixart.csv  \\\n",
       "Trial 1:0back                           -1.096793e+06   \n",
       "Trial 2:2back                           -1.054236e+06   \n",
       "Trial 3:3back                           -1.008712e+06   \n",
       "Trial 4:2back                           -9.339621e+05   \n",
       "Trial 5:3back                           -8.911006e+05   \n",
       "Trial 6:0back                           -8.770217e+05   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/025/pixart_resting.csv  \\\n",
       "Trial 1:0back                                             NaN   \n",
       "Trial 2:2back                                             NaN   \n",
       "Trial 3:3back                                             NaN   \n",
       "Trial 4:2back                                             NaN   \n",
       "Trial 5:3back                                             NaN   \n",
       "Trial 6:0back                                             NaN   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/025/inf_ecg.csv  \\\n",
       "Trial 1:0back                                -0.000094   \n",
       "Trial 2:2back                                -0.000026   \n",
       "Trial 3:3back                                -0.000045   \n",
       "Trial 4:2back                                -0.000006   \n",
       "Trial 5:3back                                 0.000093   \n",
       "Trial 6:0back                                -0.000017   \n",
       "\n",
       "               data/MAUS/Data/Raw_data/025/inf_resting.csv  \n",
       "Trial 1:0back                                          NaN  \n",
       "Trial 2:2back                                          NaN  \n",
       "Trial 3:3back                                          NaN  \n",
       "Trial 4:2back                                          NaN  \n",
       "Trial 5:3back                                          NaN  \n",
       "Trial 6:0back                                          NaN  \n",
       "\n",
       "[6 rows x 154 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = pathlib.Path(\"data/MAUS/Data/Raw_data\")\n",
    "\n",
    "final_data = pd.DataFrame()\n",
    "\n",
    "for person in data_path.iterdir():\n",
    "    for ele in pathlib.Path(person).iterdir():\n",
    "        \n",
    "        # get the data and format it\n",
    "        if str(ele)[-3:] == 'csv':\n",
    "            current_data = pd.read_csv(ele)\n",
    "            formatted_data = current_data.mean(axis=0)\n",
    "        \n",
    "        final_data[str(ele)] = formatted_data\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c58fa4fb-896f-4e17-b883-7b02826e9c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5005267447916666\n",
      "1.5005267447916666\n",
      "35.30087050781249\n",
      "-1475753.5769756096\n",
      "nan\n",
      "3.5416666666685664e-06\n",
      "nan\n",
      "1.1243548958333334\n",
      "1.1243548958333334\n",
      "35.33859920572917\n",
      "-1783655.4710243903\n",
      "nan\n",
      "-0.00011139322916666634\n",
      "nan\n",
      "2.131128984375\n",
      "2.131128984375\n",
      "35.3449972265625\n",
      "-970875.6252666666\n",
      "nan\n",
      "0.00020346354166666551\n",
      "nan\n",
      "0.10988856770833332\n",
      "0.10988856770833332\n",
      "35.318776289062505\n",
      "-1398740.397\n",
      "nan\n",
      "6.341145833339025e-06\n",
      "nan\n",
      "1.1892648437500002\n",
      "1.1892648437500002\n",
      "35.29293411458333\n",
      "-1908647.9121951219\n",
      "nan\n",
      "-4.3763020833334435e-05\n",
      "nan\n",
      "6.3220839453125\n",
      "6.3220839453125\n",
      "35.31537954427083\n",
      "-2158842.6003333335\n",
      "nan\n",
      "1.845052083333572e-05\n",
      "nan\n",
      "0.41774290364583333\n",
      "0.41774290364583333\n",
      "35.334678658854166\n",
      "-1832937.7018666666\n",
      "nan\n",
      "-8.74348958333311e-05\n",
      "nan\n",
      "1.1323379947916667\n",
      "1.1323379947916667\n",
      "35.35361979166667\n",
      "-1583103.5171333333\n",
      "nan\n",
      "1.5781250000000136e-05\n",
      "nan\n",
      "0.6063472395833333\n",
      "0.6063472395833333\n",
      "35.33992815104167\n",
      "-1337658.9422\n",
      "nan\n",
      "3.229166666669468e-06\n",
      "nan\n",
      "2.990185598958333\n",
      "2.990185598958333\n",
      "35.3063318359375\n",
      "-2956557.1041300814\n",
      "nan\n",
      "-0.00012076822916666288\n",
      "nan\n",
      "0.38444205729166664\n",
      "0.38444205729166664\n",
      "35.33226885416667\n",
      "-1450100.2987333334\n",
      "nan\n",
      "-3.338541666666402e-05\n",
      "nan\n",
      "2.4627942708333332\n",
      "2.4627942708333332\n",
      "35.288905677083335\n",
      "-973092.5108\n",
      "nan\n",
      "-8.289062499999754e-05\n",
      "nan\n",
      "1.2644038932291666\n",
      "1.2644038932291666\n",
      "35.25702638020834\n",
      "-1218392.1944666666\n",
      "nan\n",
      "0.00019156250000000168\n",
      "nan\n",
      "3.3481553906250006\n",
      "3.3481553906250006\n",
      "35.32776213541667\n",
      "-1211610.011902439\n",
      "nan\n",
      "-5.7252604166665976e-05\n",
      "nan\n",
      "1.211963984375\n",
      "1.211963984375\n",
      "35.25849055989583\n",
      "-536984.8290666667\n",
      "nan\n",
      "-5.5429687499997105e-05\n",
      "nan\n",
      "12.190922942708333\n",
      "12.190922942708333\n",
      "35.283109921875\n",
      "-1515268.44\n",
      "nan\n",
      "-0.00014216145833333404\n",
      "nan\n",
      "1.1494552864583334\n",
      "1.1494552864583334\n",
      "35.34591854166666\n",
      "-1124142.2825333334\n",
      "nan\n",
      "-1.2031249999998068e-05\n",
      "nan\n",
      "1.1535795572916667\n",
      "1.1535795572916667\n",
      "35.34419412760417\n",
      "-775718.2478\n",
      "nan\n",
      "1.7083333333333187e-05\n",
      "nan\n",
      "4.126876770833333\n",
      "4.126876770833333\n",
      "35.331614140625\n",
      "-1178690.1139333334\n",
      "nan\n",
      "1.6184895833336453e-05\n",
      "nan\n",
      "0.7587617578125001\n",
      "0.7587617578125001\n",
      "35.36500393229167\n",
      "-1611647.6561333332\n",
      "nan\n",
      "-8.549479166666638e-05\n",
      "nan\n",
      "0.21895041666666668\n",
      "0.21895041666666668\n",
      "35.352580312499995\n",
      "-867650.9403333333\n",
      "nan\n",
      "-4.6653645833330996e-05\n",
      "nan\n",
      "0.2548414453125\n",
      "0.2548414453125\n",
      "35.2777862109375\n",
      "-1096792.7355333334\n",
      "nan\n",
      "-9.40104166666652e-05\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "for ele in final_data.transpose().iloc[:,0]:\n",
    "    print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90af7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
